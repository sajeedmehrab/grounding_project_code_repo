{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b2ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information_vrpart2(output_text, x_factor, y_factor):\n",
    "    \"\"\"\n",
    "        extract bounding boxes, points, and various text fields from model output.\n",
    "        parses VRPart2 output format.\n",
    "        <think> ... </think> <target> ... </target> <object_hint> ... </object_hint> <first_answer> ... </first_answer> <criticism> ... </criticism> <answer> ... </answer>\n",
    "        this returns empty strings and lists if it does not find the expected tags in the output.\n",
    "    \"\"\"\n",
    "    # Extract think tag\n",
    "    think_pattern = r'<think>([^<]+)</think>'\n",
    "    think_match = re.search(think_pattern, output_text)\n",
    "    think_text = think_match.group(1).strip() if think_match else \"\"\n",
    "    \n",
    "    # Extract decide tag\n",
    "    decide_pattern = r'<target>([^<]+)</target>'\n",
    "    decide_match = re.search(decide_pattern, output_text)\n",
    "    decide_text = decide_match.group(1).strip() if decide_match else \"\"\n",
    "\n",
    "    # Extract object_hint tag\n",
    "    object_hint_pattern = r'<object_hint>\\s*(.*?)\\s*</object_hint>'\n",
    "    object_hint_match = re.search(object_hint_pattern, output_text, re.DOTALL)\n",
    "    object_hint_text = object_hint_match.group(1).strip() if object_hint_match else \"\"\n",
    "    \n",
    "    # Extract first_answer tag\n",
    "    first_answer_pattern = r'<first_answer>\\s*(.*?)\\s*</first_answer>'\n",
    "    first_answer_match = re.search(first_answer_pattern, output_text, re.DOTALL)\n",
    "    first_answer_text = first_answer_match.group(1).strip() if first_answer_match else \"\"\n",
    "    \n",
    "    # Extract criticism tag\n",
    "    criticism_pattern = r'<criticism>([^<]+)</criticism>'\n",
    "    criticism_match = re.search(criticism_pattern, output_text)\n",
    "    criticism_text = criticism_match.group(1).strip() if criticism_match else \"\"\n",
    "    \n",
    "    # Extract final_answer and parse bbox/points\n",
    "    final_answer_pattern = r'<answer>\\s*(.*?)\\s*</answer>'\n",
    "    final_answer_match = re.search(final_answer_pattern, output_text, re.DOTALL) \n",
    "    final_answer_text = final_answer_match.group(1).strip() if final_answer_match else \"\"\n",
    "\n",
    "    output_text_parsed = {\n",
    "        \"think\": think_text,\n",
    "        \"decide\": decide_text,\n",
    "        \"first_answer\": first_answer_text,\n",
    "        \"criticism\": criticism_text,\n",
    "        \"final_answer\": final_answer_text\n",
    "    }\n",
    "    \n",
    "    pred_bboxes = []\n",
    "    pred_points = []\n",
    "    \n",
    "    if final_answer_match:\n",
    "        data = json.loads(final_answer_match.group(1))\n",
    "        pred_bboxes = [[\n",
    "            int(item['bbox_2d'][0] * x_factor + 0.5),\n",
    "            int(item['bbox_2d'][1] * y_factor + 0.5),\n",
    "            int(item['bbox_2d'][2] * x_factor + 0.5),\n",
    "            int(item['bbox_2d'][3] * y_factor + 0.5)\n",
    "        ] for item in data]\n",
    "        pred_points = [[\n",
    "            int(item['point_2d'][0] * x_factor + 0.5),\n",
    "            int(item['point_2d'][1] * y_factor + 0.5)\n",
    "        ] for item in data]\n",
    "\n",
    "    return pred_bboxes, pred_points, output_text_parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3927259",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"<think>Finding \"fork's tines\" means identifying the points where a fork's tines meet the handle. In this context, \"fork's tines\" refers to the points where the tines begin on the fork.</think>\n",
    "<target>part</target>\n",
    "<object_hint>\n",
    "[{\"bbox_2d\": [0,96,838,840], \"point_2d\": [360,670]}]\n",
    "</object_hint>\n",
    "<first_answer>\n",
    "[{\"bbox_2d\": [160,612,417,788], \"point_2d\": [373,708]}]\n",
    "</first_answer>\n",
    "<criticism>The box is already tight and correctly placed. ADJUSTMENT: YES</criticism>\n",
    "<answer>\n",
    "[{\"bbox_2d\": [160, 579, 443, 804], \"point_2d\": [373,708]}]\n",
    "</answer>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34be72fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[160, 579, 443, 804]],\n",
       " [[373, 708]],\n",
       " {'think': 'Finding \"fork\\'s tines\" means identifying the points where a fork\\'s tines meet the handle. In this context, \"fork\\'s tines\" refers to the points where the tines begin on the fork.',\n",
       "  'decide': 'part',\n",
       "  'first_answer': '[{\"bbox_2d\": [160,612,417,788], \"point_2d\": [373,708]}]',\n",
       "  'criticism': 'The box is already tight and correctly placed. ADJUSTMENT: YES',\n",
       "  'final_answer': '[{\"bbox_2d\": [160, 579, 443, 804], \"point_2d\": [373,708]}]'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_information_vrpart2(test_string, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa40a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728551fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Load the model\n",
    "model_path = \"/data/VLMGroundingProject/ModelData/SegZero/visionreasoner_workdir/ip_vrpretrained_partreward2/global_step_224/actor/huggingface\"\n",
    "print(\"Loading model...\")\n",
    "reasoning_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "reasoning_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e57a4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response...\n",
      "\n",
      "==================================================\n",
      "Model Output:\n",
      "==================================================\n",
      "<think>In this image, the television's screen is the part of the television that displays the image. It is a rectangular area within the overall television set.</think>\n",
      "<target>part</target>\n",
      "<object_hint>[{\"bbox_2d\": [158,146,760,840], \"point_2d\": [350,230]}]</object_hint>\n",
      "<first_answer>[{\"bbox_2d\": [248,209,539,602], \"point_2d\": [390,425]}]</first_answer>\n",
      "<criticism>The box is already tight and correctly placed. ADJUSTMENT: NO</criticism>\n",
      "<answer>[{\"bbox_2d\": [248,209,539,602], \"point_2d\": [390,425]}]</answer><|im_end|>\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Set your paths and parameters\n",
    "image_path = \"/data/VLMGroundingProject/Datasets/InstructPart/test/images/4773046926_15b78b68d5_o-television-screen.jpg\"\n",
    "query_text = \"television's screen\"  \n",
    "prompt_template_path = \"/home/ksmehrab/AttentionGrounding/ModelPlaygrounds/SegZero/EvaluationScripts/Prompts/vrpart2_prompt.txt\"\n",
    "resize_size = 840\n",
    "max_response_length = 2000\n",
    "\n",
    "# Load prompt template\n",
    "with open(prompt_template_path, 'r') as f:\n",
    "    QUESTION_TEMPLATE = f.read()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "# Load and prepare image\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "resized_image = image.resize((resize_size, resize_size), Image.BILINEAR)\n",
    "\n",
    "# Prepare message\n",
    "message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"image\", \n",
    "            \"image\": resized_image\n",
    "        },\n",
    "        {   \n",
    "            \"type\": \"text\",\n",
    "            \"text\": QUESTION_TEMPLATE.format(Question=query_text.lower().strip(\".\"))\n",
    "        }\n",
    "    ]\n",
    "}]\n",
    "\n",
    "# Prepare inputs\n",
    "text = processor.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info([message])\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Generate output\n",
    "print(\"Generating response...\")\n",
    "with torch.inference_mode():\n",
    "    generated_ids = reasoning_model.generate(\n",
    "        **inputs, \n",
    "        use_cache=True, \n",
    "        max_new_tokens=max_response_length, \n",
    "        do_sample=False\n",
    "    )\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] \n",
    "        for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, \n",
    "        skip_special_tokens=False, \n",
    "        clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "\n",
    "# Print the output\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Output:\")\n",
    "print(\"=\"*50)\n",
    "print(output_text)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a65ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segzero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
