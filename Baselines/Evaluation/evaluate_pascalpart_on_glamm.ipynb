{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8283f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ksmehrab/AttentionGrounding/Baselines/Datasets')\n",
    "sys.path.append('/home/ksmehrab/AttentionGrounding/Baselines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f59efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pascalpart import get_pascalpart_masks\n",
    "from utils import read_txt_file\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6305f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_image_dir = \"/data/Pascal_VOC_2012/VOCdevkit/VOC2012/JPEGImages\" # 17125 images\n",
    "annotations_path= \"/data/PartSegmentationDatasets/PascalPart/Annotations_Part\"\n",
    "val_filepath = \"/data/PartSegmentationDatasets/PascalPart/val.txt\" # 925 images. File contains just the file prefix. Add .jpg extension for images, and .mat extension for annotations\n",
    "base_pred_dir = \"/data/VLMGroundingProject/BaselineResults/PascalPartCrops/GLAMM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "300517a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following if you want to evaluate on all images\n",
    "# val_filenames = read_txt_file(val_filepath)\n",
    "# req_filenames = val_filenames\n",
    "\n",
    "# Evaluate only on existing results \n",
    "req_filenames = os.listdir(base_pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2aff8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_masks(masks):\n",
    "    combined_mask = masks[0]\n",
    "    for i in range(1, len(masks)):\n",
    "        combined_mask = combined_mask | masks[i]\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1edbf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainercv.evaluations import calc_semantic_segmentation_confusion\n",
    "def compute_miou(preds, gts):\n",
    "    '''\n",
    "    This function takes two lists as inputs, where:\n",
    "    preds: [list of 2-D prediction where each pixel corresponds to pixel-label]\n",
    "    gts: [list of ground-truths in 2-D space, contains -1 value for critical pixels]\n",
    "    \n",
    "    returns mean of the iou for all classes\n",
    "    '''\n",
    "    confusion = calc_semantic_segmentation_confusion(preds, gts)\n",
    "\n",
    "    gtj = confusion.sum(axis=1)\n",
    "    resj = confusion.sum(axis=0)\n",
    "    gtjresj = np.diag(confusion)\n",
    "    denominator = gtj + resj - gtjresj\n",
    "    iou = gtjresj / denominator\n",
    "\n",
    "    return iou, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "117f9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glamm_predicted_mask(base_pred_dir, filename_prefix, class_name, is_crop=False):\n",
    "    \"\"\"\n",
    "        Get the predicted mask for a given image and class from GLAMM predictions.\n",
    "        Args:\n",
    "            base_pred_dir (str): Base directory where GLAMM predictions are stored.\n",
    "            filename_prefix (str): Prefix of the filename (without extension).\n",
    "            class_name (str): Name of the class for which the mask is required.\n",
    "    \"\"\"\n",
    "    class_name = class_name.replace(\" \", \"_\")\n",
    "    # all pred masks for this filename is in a directory named filename_prefix\n",
    "    pred_masks_dir = os.path.join(base_pred_dir, filename_prefix)\n",
    "    # the required mask is in a file named class_name.png. here, class_name can either be the object class (like person) or the object || part class (like person_head)\n",
    "    if not is_crop:\n",
    "        req_pred_mask = os.path.join(pred_masks_dir, class_name + \".png\")\n",
    "    else:\n",
    "        req_pred_mask = os.path.join(pred_masks_dir, class_name+'_crop' + \".png\")\n",
    "    # Load the mask\n",
    "    mask = Image.open(req_pred_mask).convert(\"L\")  # grayscale\n",
    "\n",
    "    # Convert to numpy, then 0/1\n",
    "    mask_np = np.array(mask)\n",
    "    binary_mask = (mask_np > 0).astype(np.uint8)\n",
    "    \n",
    "    return binary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/83 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of ground truth and prediction should be same.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 43\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# obj_iou_w_bg, obj_confusion = compute_miou(pred_obj_masks, gt_obj_masks)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# obj_ious.append(obj_iou_w_bg[1]) # only taking the iou of the object class, not the background\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m part_iou_w_bg, part_confusion \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_miou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_part_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_part_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m part_ious\u001b[38;5;241m.\u001b[39mappend(part_iou_w_bg[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# only taking the iou of the part class, not the background\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m, in \u001b[0;36mcompute_miou\u001b[0;34m(preds, gts)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_miou\u001b[39m(preds, gts):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    This function takes two lists as inputs, where:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    preds: [list of 2-D prediction where each pixel corresponds to pixel-label]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    returns mean of the iou for all classes\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     confusion \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_semantic_segmentation_confusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     gtj \u001b[38;5;241m=\u001b[39m confusion\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m     resj \u001b[38;5;241m=\u001b[39m confusion\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/data_env/lib/python3.9/site-packages/chainercv/evaluations/eval_semantic_segmentation.py:37\u001b[0m, in \u001b[0;36mcalc_semantic_segmentation_confusion\u001b[0;34m(pred_labels, gt_labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim of labels should be two.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_label\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m gt_label\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of ground truth and prediction should\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m be same.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m pred_label \u001b[38;5;241m=\u001b[39m pred_label\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     40\u001b[0m gt_label \u001b[38;5;241m=\u001b[39m gt_label\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of ground truth and prediction should be same."
     ]
    }
   ],
   "source": [
    "# comment out the object related code if you want to compute only part ious\n",
    "# obj_ious = []\n",
    "part_ious = []\n",
    "count_no_obj = 0\n",
    "for filename in tqdm(req_filenames):\n",
    "    # gt_obj_masks = []\n",
    "    # pred_obj_masks = []\n",
    "\n",
    "    gt_part_masks = []\n",
    "    pred_part_masks = []\n",
    "\n",
    "    img_filepath = os.path.join(pascal_image_dir, filename+'.jpg')\n",
    "\n",
    "    annot_filename = filename + '.mat'\n",
    "    anno_dict = get_pascalpart_masks(annot_filename, annotations_path, images_path=pascal_image_dir)\n",
    "\n",
    "    for obj_name, anno in anno_dict.items():\n",
    "        # obj_masks = anno['object_maps']\n",
    "        # obj_mask = combine_masks(obj_masks)\n",
    "        # gt_obj_masks.append(obj_mask)\n",
    "        # pred_obj_mask = get_glamm_predicted_mask(base_pred_dir, filename, obj_name)\n",
    "        # pred_obj_masks.append(pred_obj_mask)\n",
    "\n",
    "        parts_masks = anno['parts']\n",
    "        for part_name, masks in parts_masks.items():\n",
    "            part_mask = combine_masks(masks)\n",
    "            gt_part_masks.append(part_mask)\n",
    "            part_full_name = obj_name + \"_\" + part_name\n",
    "            pred_part_mask = get_glamm_predicted_mask(base_pred_dir, filename, part_full_name, is_crop=True)\n",
    "            pred_part_masks.append(pred_part_mask)\n",
    "\n",
    "    if len(pred_part_masks) == 0:\n",
    "        # no part present in this image\n",
    "        print(f'no parts present in {filename}, skipping...')\n",
    "        count_no_obj += 1\n",
    "        continue\n",
    "    \n",
    "    # obj_iou_w_bg, obj_confusion = compute_miou(pred_obj_masks, gt_obj_masks)\n",
    "    # obj_ious.append(obj_iou_w_bg[1]) # only taking the iou of the object class, not the background\n",
    "\n",
    "\n",
    "    part_iou_w_bg, part_confusion = compute_miou(pred_part_masks, gt_part_masks)\n",
    "    part_ious.append(part_iou_w_bg[1]) # only taking the iou of the part class, not the background\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19fc511c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910982110167357"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(obj_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afb95dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22074454816350528"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(part_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef90fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segzero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
