{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0a709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883d37e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891b79d0389c4cfebd396fa44d90abcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac078feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0b6cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97712b9",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cead9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_id = 'lmms-lab/multimodal-open-r1-8k-verified'\n",
    "train_dataset = load_dataset(dataset_id, split='train[:5%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220ab548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=251x275>,\n",
       " 'problem': \"Based on the image, if segment DE is extended while maintaining the angle at point D constant, what will be the effect on the value of 's'? Choose the correct answer from the options below:\\nChoices:\\nA. Increase 's'\\nB. Decrease 's'\\nC. No change\\nD. Make 's' negative\",\n",
       " 'solution': \"<think>Let's consider the relationship between the length of segment DE and the value of 's'. The value of 's' is influenced by both the length of DE and the sine of the angle at point D. Since the angle remains constant, the sine of the angle does not change. Therefore, the only factor affecting 's' is the length of DE. As DE is extended, its length increases, which in turn increases the value of 's'. Hence, the correct answer is A.</think>\\n\\n<answer>A</answer>\",\n",
       " 'original_question': \"According to the question shown in the image, please first perform reasoning, then finally select the right answer from the choices, e.g., Answer: xxx.\\nQuestion: Based on the image, if segment DE is extended, how does it affect 's' while keeping the angle constant?\\nChoices:\\nA. Increase 's'\\nB. Decrease 's'\\nC. No change\\nD. Make 's' negative\",\n",
       " 'original_answer': \"Extending segment DE while keeping the angle constant will increase 's', as 's' is a function of both length and the sine of the angle, which remains unchanged. So the answer is A\\nAnswer: A\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56162d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "model_name = \"Qwen/Qwen3-VL-4B-Instruct\" # \"Qwen/Qwen3-VL-8B-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_name, padding_side=\"left\")\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful AI Assistant that provides well-reasoned and detailed responses. \"\n",
    "    \"You first think about the reasoning process as an internal monologue and then provide the user with the answer. \"\n",
    "    \"Respond in the following format: \\n...\\n\\n\\n...\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "def make_conversation(example):\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": example[\"image\"]},\n",
    "                {\"type\": \"text\", \"text\": example[\"problem\"]},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"image\": example[\"image\"],\n",
    "    }\n",
    "\n",
    "train_dataset = train_dataset.map(make_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81752882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns(['problem', 'original_question', 'original_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee7d547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=251x275>,\n",
       " 'solution': \"<think>Let's consider the relationship between the length of segment DE and the value of 's'. The value of 's' is influenced by both the length of DE and the sine of the angle at point D. Since the angle remains constant, the sine of the angle does not change. Therefore, the only factor affecting 's' is the length of DE. As DE is extended, its length increases, which in turn increases the value of 's'. Hence, the correct answer is A.</think>\\n\\n<answer>A</answer>\",\n",
       " 'prompt': \"<|im_start|>system\\nYou are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: \\n...\\n\\n\\n...\\n<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Based on the image, if segment DE is extended while maintaining the angle at point D constant, what will be the effect on the value of 's'? Choose the correct answer from the options below:\\nChoices:\\nA. Increase 's'\\nB. Decrease 's'\\nC. No change\\nD. Make 's' negative<|im_end|>\\n<|im_start|>assistant\\n\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91463a9",
   "metadata": {},
   "source": [
    "## Load Model. Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a92401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc4ab0de4874a74bf3e1d37de64d166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Qwen3VLForConditionalGeneration, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    model_name, dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa165d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# update target_modules -> merger.linear_fc2 and deepstack_merger_list.linear_fc2 if we want to fine-tune the VL projection layers as well \n",
    "# reduced dropout to 0.05 since our dataset is small and to avoid underfitting\n",
    "# increased lora_alpha to 32 to give more weight to the low-rank updates \n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9016b6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = \"\"\"<think>Let's think through this step-by-step. The height of the pole can be calculated using the tangent of the angle, which is given by the formula: height = distance * tan(angle). In this case, the distance is 10 meters, and the angle is 70 degrees. If the angle decreases, the tangent of the angle also decreases because the tangent function increases with increasing angles in the range from 0 to 90 degrees. Therefore, the height calculated using this tangent value will also decrease.</think>\n",
    "\n",
    "<answer>B</answer>\"\"\"\n",
    "parse(\n",
    "    sol,\n",
    "    extraction_mode=\"first_match\",\n",
    "    extraction_config=[\n",
    "                LatexExtractionConfig(\n",
    "                    normalization_config=NormalizationConfig(\n",
    "                        nits=False,\n",
    "                        malformed_operators=False,\n",
    "                        basic_latex=True,\n",
    "                        equations=True,\n",
    "                        boxed=True,\n",
    "                        units=True,\n",
    "                    ),\n",
    "                    boxed_match_priority=0,\n",
    "                    try_extract_without_anchor=False,\n",
    "                )\n",
    "            ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be4a45",
   "metadata": {},
   "source": [
    "## Reward fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the reasoning process is enclosed within  and  tags, while the final answer is enclosed within  and  tags.\"\"\"\n",
    "    pattern = r\"^\\n.*?\\n\\n\\n.*?\\n$\"\n",
    "    matches = [re.match(pattern, content, re.DOTALL | re.MULTILINE) for content in completions]\n",
    "    return [1.0 if match else 0.0 for match in matches]\n",
    "\n",
    "from math_verify import LatexExtractionConfig, parse, verify\n",
    "from latex2sympy2_extended import NormalizationConfig\n",
    "\n",
    "\n",
    "def len_reward(completions, solution, **kwargs) -> float:\n",
    "    \"\"\"Compute length-based rewards to discourage overthinking and promote token efficiency.\n",
    "\n",
    "    Taken from the Kimi 1.5 tech report: https://huggingface.co/papers/2501.12599\n",
    "\n",
    "    Args:\n",
    "        completions: List of model completions\n",
    "        solution: List of ground truth solutions\n",
    "\n",
    "    Returns:\n",
    "        List of rewards where:\n",
    "        - For correct answers: reward = 0.5 - (len - min_len)/(max_len - min_len)\n",
    "        - For incorrect answers: reward = min(0, 0.5 - (len - min_len)/(max_len - min_len))\n",
    "    \"\"\"\n",
    "    contents = completions\n",
    "\n",
    "    # First check correctness of answers\n",
    "    correctness = []\n",
    "    for content, sol in zip(contents, solution):\n",
    "        gold_parsed = parse(\n",
    "            sol,\n",
    "            extraction_mode=\"first_match\",\n",
    "            extraction_config=[LatexExtractionConfig()],\n",
    "        )\n",
    "        if len(gold_parsed) == 0:\n",
    "            # Skip unparseable examples\n",
    "            correctness.append(True)  # Treat as correct to avoid penalizing\n",
    "            print(\"Failed to parse gold solution: \", sol)\n",
    "            continue\n",
    "\n",
    "        answer_parsed = parse(\n",
    "            content,\n",
    "            extraction_config=[\n",
    "                LatexExtractionConfig(\n",
    "                    normalization_config=NormalizationConfig(\n",
    "                        nits=False,\n",
    "                        malformed_operators=False,\n",
    "                        basic_latex=True,\n",
    "                        equations=True,\n",
    "                        boxed=True,\n",
    "                        units=True,\n",
    "                    ),\n",
    "                    boxed_match_priority=0,\n",
    "                    try_extract_without_anchor=False,\n",
    "                )\n",
    "            ],\n",
    "            extraction_mode=\"first_match\",\n",
    "        )\n",
    "        correctness.append(verify(answer_parsed, gold_parsed))\n",
    "\n",
    "    # Calculate lengths\n",
    "    lengths = [len(content) for content in contents]\n",
    "    min_len = min(lengths)\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    # If all responses have the same length, return zero rewards\n",
    "    if max_len == min_len:\n",
    "        return [0.0] * len(completions)\n",
    "\n",
    "    rewards = []\n",
    "    for length, is_correct in zip(lengths, correctness):\n",
    "        lambda_val = 0.5 - (length - min_len) / (max_len - min_len)\n",
    "\n",
    "        if is_correct:\n",
    "            reward = lambda_val\n",
    "        else:\n",
    "            reward = min(0, lambda_val)\n",
    "\n",
    "        rewards.append(float(reward))\n",
    "\n",
    "    return rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b7bcf",
   "metadata": {},
   "source": [
    "## GRPO Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02207c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig\n",
    "\n",
    "output_dir = \"Qwen3-VL-4B-Instruct-trl-grpo\"\n",
    "\n",
    "# Configure training arguments using GRPOConfig\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate=2e-5,\n",
    "    #num_train_epochs=1,\n",
    "    max_steps=10,                                        # Number of dataset passes. For full trainings, use `num_train_epochs` instead\n",
    "\n",
    "    # Parameters that control the data preprocessing\n",
    "    per_device_train_batch_size=2,\n",
    "    max_completion_length=1024, # default: 256            # Max completion length produced during training\n",
    "    num_generations=2, # 2, # default: 8                  # Number of generations produced during trainig for comparison\n",
    "    max_prompt_length=2048, # default: 512                # Max prompt lenght of the input prompt used for generation during training\n",
    "\n",
    "    fp16=True,\n",
    "\n",
    "    # Parameters related to reporting and saving\n",
    "    output_dir=output_dir,                                # Where to save model checkpoints and logs\n",
    "    logging_steps=1,                                      # Log training metrics every N steps\n",
    "    report_to=\"trackio\",                                  # Experiment tracking tool\n",
    "\n",
    "    # Hub integration\n",
    "    push_to_hub=True,\n",
    "    log_completions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ebcf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOTrainer\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=[format_reward, len_reward],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a26ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4d75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA L40. Max memory = 44.428 GB.\n",
      "2.082 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8c75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391.6479 seconds used for training.\n",
      "6.53 minutes used for training.\n",
      "Peak reserved memory = 11.984 GB.\n",
      "Peak reserved memory for training = 9.902 GB.\n",
      "Peak reserved memory % of max memory = 26.974 %.\n",
      "Peak reserved memory for training % of max memory = 22.288 %.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239db138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
